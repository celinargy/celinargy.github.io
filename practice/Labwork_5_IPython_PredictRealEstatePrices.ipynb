{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5 - Predicting Real Estate Data in St. Petersburg\n",
    "We have data from Yandex.Realty classified https://realty.yandex.ru containing real estate listings for apartments in St. Petersburg and Leningrad Oblast from 2016 till the middle of August 2018. In this Lab you'll learn how to apply machine learning algorithms to solve business problems. Accurate price prediction can help to find fraudsters automatically and help Yandex.Realty users to make better decisions when buying and selling real estate.\n",
    "\n",
    "Using python with machine learning algotithms is the #1 option for prototyping solutions among data scientists today. We'll take a look at it in this lab.\n",
    "\n",
    "### Main objectives\n",
    "After successful completion of the lab work students will be able to:\n",
    "-\tPrepare datasets for machine learning algorithms\n",
    "-\tApply machine learning for solving price prediction problem\n",
    "-   Calculate metrics which can help us find out whether our machine learning model is ready for production\n",
    "\n",
    "### Tasks\n",
    "-\tClean dataset\n",
    "-\tSplit dataset to test, train and validation datasets\n",
    "-\tApply decision tree algorithm to build ML (machine learning) model for price predictions\n",
    "-   Calculate business metrics\n",
    "-   Try other algorithms and factors to get a better solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data with real estate prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import pandas library and set options to be able to view data right in the browser\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math library which we'll need later for calculating metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dataset and see which data it contains.\n",
    "spb_df = pd.read_table('../data/spb.real.estate.archive.2018.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at random sample of the loaded dataset to understand what's inside\n",
    "spb_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check how much data to we have\n",
    "len(spb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare cleaned dataset with RENT data in St.Peterburg without Oblast \n",
    "<p>Use results of our analysis of the previous Lab Works for cleaning the dataset\n",
    "<p>Reminder: offer_type column contains data to distinct rent from sell items, 2 stands for RENT, 1 for SELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataframe with rent data in city limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_df = spb_df[spb_df.offer_type == 2]\n",
    "print(\"Total rent data size: {}\".format(len(rent_df)))\n",
    "rent_df_spb = rent_df[rent_df.unified_address.str.contains('Россия, Санкт-Петербург')]\n",
    "print(\"Rent data size in city limits: {}\".format(len(rent_df_spb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate price per square meter, get median prices for house and find outliers with the help of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate price per sq m\n",
    "rent_df_spb['price_per_sq_m'] = rent_df_spb.last_price/rent_df.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find median price per sq m per house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_rent_df = rent_df_spb.groupby('unified_address').price_per_sq_m.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_rent_df.rename(columns = {'price_per_sq_m': 'house_price_sqm_median'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge rent data with house median prices and inspect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_df_spb = rent_df_spb.merge(house_rent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean data from the outliers - use results from Lab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_df_cleaned = rent_df_spb[~((rent_df_spb.price_per_sq_m/rent_df_spb.house_price_sqm_median) > 5)]\n",
    "rent_df_cleaned = rent_df_cleaned[rent_df_cleaned.last_price < 1000000]\n",
    "rent_df_cleaned = rent_df_cleaned[~((rent_df_cleaned.price_per_sq_m > 3000) \n",
    "                                     & ((rent_df_cleaned.house_price_sqm_median < 1000) \n",
    "                                        | (rent_df_cleaned.house_price_sqm_median == rent_df_cleaned.price_per_sq_m)))]\n",
    "rent_df_cleaned = rent_df_cleaned[~((rent_df_cleaned.price_per_sq_m < 250) \n",
    "                               & (rent_df_cleaned.house_price_sqm_median/rent_df_cleaned.price_per_sq_m >= 2))]\n",
    "rent_df_cleaned = rent_df_cleaned[~((rent_df_cleaned.price_per_sq_m < 200) \n",
    "                                          & (rent_df_cleaned.price_per_sq_m == rent_df_cleaned.house_price_sqm_median))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets training, testing and a holdout dataset.\n",
    "We need a holdout dataset to assess the final quality of the algorithm. When several teams create their models based on different models and factors, holdout dataset is used to compare results.\n",
    "Testing dataset can be used to test models and tune hyperparameters.\n",
    "Since our model will be used to predict prices for new offers based on the old data, it's a good option to select split by time instead of just random split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all offers added the first 3 months of 2018 as train dataset.\n",
    "# '&' means 'and' and should be used when both conditions are satisfied\n",
    "# pay attention that it's better always to put conditions in brackets to embrace the right priority of operations\n",
    "train_df = rent_df_cleaned[(rent_df_spb.first_day_exposition >= '2018-01-01') \n",
    "                          & (rent_df_spb.first_day_exposition < '2018-04-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all offers added in april and may 2018 as test dataset.\n",
    "test_df = rent_df_cleaned[(rent_df_spb.first_day_exposition >= '2018-04-01') \n",
    "                          & (rent_df_spb.first_day_exposition < '2018-06-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use latest data from 2018-06-01 as a hodout dataset to simulate how algorithms would\n",
    "# behave in production\n",
    "holdout_df = rent_df_cleaned[rent_df_spb.first_day_exposition >= '2018-06-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(holdout_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = rent_df_cleaned[rent_df_spb.first_day_exposition < '2018-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ML model with catboost library for predicting real estate prices and test it using business metrics\n",
    "#### Create functions to test our model using appropriate business metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy library for fast mathematical operations over arrays\n",
    "# use 'np'  as a short alias\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an utility function which takes real and predicted Series and calculate\n",
    "# MAPE - mean absolute percentage error\n",
    "# we have to implement this functions ourselves, because there is no \n",
    "# standart implementation in sklearn module\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    # use np.array function to make an array out of pd.Series object passed \n",
    "    # for further processing with numpy\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    # for each row let's calculate how much our predicted prices differ from real prices\n",
    "    # np.abs calculates calculate the absolute value element-wise\n",
    "    diff_true_pred_ration = np.abs((y_true - y_pred) / y_true)\n",
    "    # calculate the mean value of the difference ratios across all items\n",
    "    # and multiply by 100 to get percentages\n",
    "    return np.mean(diff_true_pred_ration) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math library which we'll need later for calculating metrics\n",
    "import math\n",
    "# import functions for calculating metrics from sklearn library\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let'ts remind ourselved on what actually these metrics mean and how are they calculated\n",
    "r2_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line to see the documentation on mean_absolute_error\n",
    "# mean_absolute_error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line to see the documentation on mean_squared_error\n",
    "# mean_squared_error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an utility functions to round prices to 1000 rubles\n",
    "def round_price_to_1000_rubles(price):\n",
    "    return int((price + 500) / 1000) * 1000\n",
    "# let's test, whether this function works correctly\n",
    "print(round_price_to_1000_rubles(22000))\n",
    "print(round_price_to_1000_rubles(22300))\n",
    "print(round_price_to_1000_rubles(22500))\n",
    "print(round_price_to_1000_rubles(22600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an utility function which tests the model passed datasets\n",
    "# and prints all important business metrics\n",
    "\n",
    "# in our case business is most interested in MAPE (mean absolute percentage error) \n",
    "# and percentiles for error rates to understand for which percentage of offers we would have\n",
    "# certain levels of model quality\n",
    "\n",
    "# analysts might also look at RMSE (root mean squared error), R2_score, \n",
    "# MAE (mean average error) to compare the models\n",
    "# returns predicted prices and percentage of error in prediction\n",
    "def test_model(model, X_test, y_test):\n",
    "    # use model to get predicted results on the passed dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # round predicted prices to 1000 rubles\n",
    "    # map function applies passed function to each element in y_pred array, but it does it in a lazy way, \n",
    "    # it doesn't do anything until we iterate over each element, that's why we call list to make a list,\n",
    "    # under the hood it applies function to the element and append it to the final list\n",
    "    # finally we have rounded values of predicted prices\n",
    "    y_pred = list(map(round_price_to_1000_rubles, y_pred))\n",
    "    \n",
    "    # let's calculate share of error between predicted and real prices\n",
    "    # zip function allows to return a list of tuples of elements of the same index from 2 lists of the same size\n",
    "    error_percents = list(((math.fabs(pred - test) / test) for (pred, test) in zip(y_pred, y_test.values)))\n",
    "    \n",
    "    # print out all metrics we need for analysis and model comparisons\n",
    "    print(\" \")\n",
    "    print(\"rmse: \" + str(math.sqrt(mean_squared_error(y_test, y_pred))) + \"  \")\n",
    "    print(\"r2_score: \" + str(r2_score(y_test, y_pred)) + \"  \")\n",
    "    print(\"mae: \" + str(mean_absolute_error(y_test, y_pred)) + \"  \")\n",
    "    print(\"mape: \" + str(mean_absolute_percentage_error(y_test, y_pred)) + \"  \")\n",
    "    \n",
    "    # print out which maximum error we have for each percentile\n",
    "    for percent in [50, 83, 90, 95, 99]:\n",
    "        print(str(percent) + \" percentile: %.1f%%\" % (np.percentile(error_percents, percent) * 100.0))\n",
    "    return y_pred, error_percents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function which will build catboost model and calculate quality metrics on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ML method for regression from catboost library\n",
    "from catboost import CatBoostRegressor\n",
    "# train catboost regression model on the passed training data and return final trained model\n",
    "def train_catboost_model(X_train, y_train, \n",
    "                         # set default hyperparameters, you can read about them \n",
    "                         # in documenation\n",
    "                         # feel free to play with them and test results on train and test sets\n",
    "                         learning_rate=0.08,\n",
    "                         n_estimators=1500,\n",
    "                         max_depth=7,\n",
    "                         nthread=10,\n",
    "                         seed=27):\n",
    "    # create the catBoost machine learning model\n",
    "    model = CatBoostRegressor(iterations=n_estimators, \n",
    "                                 depth=max_depth,\n",
    "                                 learning_rate=learning_rate,\n",
    "                                 logging_level='Silent',\n",
    "                                 thread_count=nthread,\n",
    "                                 random_seed=seed)\n",
    "    # train the model on training dataset\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at what data do we have which we can use in predicting apartment prices\n",
    "list(rent_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try these factors first\n",
    "factors = ['floor', 'open_plan', 'rooms', 'studio', \n",
    "         'area', 'kitchen_area', 'living_area', 'renovation' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[factors]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['last_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train catboost regression model, it will take some time\n",
    "model = train_catboost_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at how it performs on our training data\n",
    "y_pred_train, error_percents_train = test_model(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at how it performs on testing data\n",
    "X_test = test_df[factors]\n",
    "y_test = test_df.last_price\n",
    "y_pred_test, error_percents_test = test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pause and think\n",
    "We see that on the test set we get worse results, how do you think why this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-control stops\n",
    "1. What other factors might influence price? Think of the factors which can be actually calculated and included in the model.\n",
    "2. Compete with other teams to create the best solution. You can play with factors and algorithm parameters to come up with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
